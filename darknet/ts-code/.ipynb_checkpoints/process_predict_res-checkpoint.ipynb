{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process predict results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取predict结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../results\"\n",
    "classes = [\"ASCUS\", \"LSIL\", \"ASCH\", \"HSIL\", \"SCC\", \"AGC1\", \"AGC2\", \"ADC\", \"EC\", \"FUNGI\", \"TRI\", \"CC\", \"ACTINO\", \"VIRUS\"]\n",
    "\n",
    "results_file_list = os.listdir(result_dir)\n",
    "# class & result file name\n",
    "dict_class_file = {}\n",
    "dict_class_predict_info = {}\n",
    "dict_class_pic_box_info = {}\n",
    "\n",
    "for file_name in results_file_list:\n",
    "    for class_name in classes:\n",
    "        if (-1 != file_name.find(class_name)):\n",
    "            dict_class_file[class_name] = file_name\n",
    "\n",
    "for class_name in dict_class_file:\n",
    "    file_name = dict_class_file[class_name]\n",
    "    file_path = result_dir + \"/\" +file_name\n",
    "    with open(file_path) as file_object:\n",
    "        predict_info = file_object.read()\n",
    "    dict_class_predict_info[class_name] = predict_info\n",
    "    \n",
    "for class_name in classes:\n",
    "    all_predict_info = dict_class_predict_info[class_name].split(\"\\n\")\n",
    "    dict_pic_box_info = {}\n",
    "    for predict_info in all_predict_info:\n",
    "        predict_info_list = predict_info.split(\" \")\n",
    "        if (len(predict_info_list) == 6):\n",
    "            box_info = predict_info_list[1] + \" \" + predict_info_list[2] + \" \" + \\\n",
    "                       predict_info_list[3] + \" \" + predict_info_list[4] + \" \" + \\\n",
    "                       predict_info_list[5]\n",
    "            pic_box = []\n",
    "            pic_box.append(box_info)\n",
    "            pic_box.append(box_info)\n",
    "            if (True == (predict_info_list[0] in dict_pic_box_info)):\n",
    "                temp_pic_box = dict_pic_box_info[predict_info_list[0]]\n",
    "                temp_pic_box.append(box_info)\n",
    "                dict_pic_box_info[predict_info_list[0]] = temp_pic_box\n",
    "            else:\n",
    "                dict_pic_box_info[predict_info_list[0]] = pic_box   \n",
    "    dict_class_pic_box_info[class_name] = dict_pic_box_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pic_info = {}\n",
    "dict_class_info = {}\n",
    "\n",
    "for index, class_name in enumerate(classes):\n",
    "    dict_pic_box = dict_class_pic_box_info[class_name]\n",
    "    for pic_name in dict_pic_box:\n",
    "        class_box_list = dict_pic_box[pic_name]\n",
    "        for i, class_box in enumerate(class_box_list):\n",
    "            class_box_list[i] = str(index) + \" \" + class_box_list[i]\n",
    "        if (False == (pic_name in dict_pic_info)):\n",
    "            dict_pic_info[pic_name] = class_box_list\n",
    "        else:\n",
    "            dict_pic_info[pic_name] = dict_pic_info[pic_name] + class_box_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dict_pic_info)\n",
    "# This format is \"PIC:['CLASS DET X1 Y1 X2 Y2', 'CLASS DET X1 Y1 X2 Y2']\" \n",
    "# dict_pic_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "validata_dir = \"../ts-own/validateImage\"\n",
    "classes = [\"ASCUS\", \"LSIL\", \"ASCH\", \"HSIL\", \"SCC\", \"AGC1\", \"AGC2\", \"ADC\", \"EC\", \"FUNGI\", \"TRI\", \"CC\", \"ACTINO\", \"VIRUS\"]\n",
    "validata_file_list = os.listdir(validata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_txt_file_set = set()\n",
    "for file_name in validata_file_list:\n",
    "    common_name = file_name.split(\".\")[0]\n",
    "    validate_txt_file_set.add(common_name)\n",
    "\n",
    "dict_pic_label_box_info = {}\n",
    "\n",
    "for file_name in validate_txt_file_set:\n",
    "    file_path = validata_dir + \"/\" + file_name + \".txt\"\n",
    "    with open(file_path) as file_object:\n",
    "        lebel_info = file_object.read()\n",
    "    lebel_info = lebel_info.split(\"\\n\")[:-1]\n",
    "    dict_pic_label_box_info[file_name] = lebel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dict_pic_label_box_info)\n",
    "# This format is \"PIC:['CLASS X Y W H', 'CLASS X Y W H']\" \n",
    "#dict_pic_label_box_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较结果和标签，得出性能评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-219-feaaaacf3f7c>, line 95)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-219-feaaaacf3f7c>\"\u001b[0;36m, line \u001b[0;32m95\u001b[0m\n\u001b[0;31m    for label_object in labels_in_single_pic:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def cal_IOU(Reframe,GTframe):\n",
    "    \"\"\"\n",
    "    自定义函数，计算两矩形 IOU，传入为均为矩形对角线，（x,y）  坐标。\n",
    "    \"\"\"\n",
    "    x1 = Reframe[0]\n",
    "    y1 = Reframe[1]\n",
    "    width1 = Reframe[2]-Reframe[0]\n",
    "    height1 = Reframe[3]-Reframe[1]\n",
    "\n",
    "    x2 = GTframe[0]\n",
    "    y2 = GTframe[1]\n",
    "    width2 = GTframe[2]-GTframe[0]\n",
    "    height2 = GTframe[3]-GTframe[1]\n",
    "\n",
    "    endx = max(x1+width1,x2+width2)\n",
    "    startx = min(x1,x2)\n",
    "    width = width1+width2-(endx-startx)\n",
    "\n",
    "    endy = max(y1+height1,y2+height2)\n",
    "    starty = min(y1,y2)\n",
    "    height = height1+height2-(endy-starty)\n",
    "\n",
    "    if width <=0 or height <= 0:\n",
    "        ratio = 0 # 重叠率为 0 \n",
    "    else:\n",
    "        Area = width*height # 两矩形相交面积\n",
    "        Area1 = width1*height1\n",
    "        Area2 = width2*height2\n",
    "        ratio = Area*1./(Area1+Area2-Area)\n",
    "    # return IOU\n",
    "    return ratio,Reframe,GTframe\n",
    "\n",
    "# yolo label like x,y,w,h\n",
    "# result like x1,y1,x2,y2\n",
    "def trans_yolo_label(txt_label):\n",
    "    x = txt_label[0] * 1216\n",
    "    y = txt_label[1] * 1216\n",
    "    w = txt_label[2] * 1216\n",
    "    h = txt_label[3] * 1216\n",
    "    \n",
    "    x1 = x - (w / 2)\n",
    "    y1 = y - (h / 2)\n",
    "    x2 = x + (w / 2)\n",
    "    y2 = y + (h / 2)\n",
    "    \n",
    "    return([x1, y1, x2, y2])\n",
    "\n",
    "def trans_str_2_numlist(num_str):\n",
    "    num_str_list = num_str.split(\" \")\n",
    "    num_list = []\n",
    "    for i, num_str in enumerate(num_str_list):\n",
    "        if i == 0:\n",
    "            num_list.append(int(num_str)) \n",
    "        else:\n",
    "            num_list.append(float(num_str)) \n",
    "    return num_list\n",
    "\n",
    "def trans_strinfo_label(str_info):\n",
    "    info_list = []\n",
    "    for str_single_box in str_info:\n",
    "        info = trans_str_2_numlist(str_single_box)\n",
    "        info[1:] = trans_yolo_label(info[1:])\n",
    "        info_list.append(info)\n",
    "        \n",
    "    return info_list\n",
    "\n",
    "def trans_strinfo_pediction(str_info):\n",
    "    info_list = []\n",
    "    for str_single_box in str_info:\n",
    "        info_list.append(trans_str_2_numlist(str_single_box))\n",
    "    return info_list\n",
    "\n",
    "def delele_same_predictions(predictions):\n",
    "    new_predictions = []\n",
    "    for prediction in predictions:\n",
    "        if prediction not in new_predictions:\n",
    "            new_predictions.append(prediction)\n",
    "    return new_predictions\n",
    "\n",
    "def cal_recall_count(label_object_count, prediction_object_count, labels_in_single_pic, predictions_in_single_pic):\n",
    "    for label_object in labels_in_single_pic:\n",
    "        label_object_count[label_object[0]] += 1\n",
    "'''\n",
    "    for prediction_object in predictions_in_single_pic:\n",
    "        if( prediction_object[1] > 0.05):\n",
    "            max_IOU = 0\n",
    "            for label_object in labels_in_single_pic:\n",
    "                if (prediction_object[0] == label_object[0]):\n",
    "                    IOU = cal_IOU(prediction_object[2:],label_object[1:])\n",
    "                    if (IOU[0] > max_IOU):\n",
    "                        max_IOU = IOU[0]\n",
    "            if (max_IOU > 0.3):\n",
    "                prediction_object_count[prediction_object[0]] += 1\n",
    "'''\n",
    "    for label_object in labels_in_single_pic:\n",
    "        max_IOU = 0\n",
    "        for prediction_object in predictions_in_single_pic:\n",
    "            if (prediction_object[0] == label_object[0]):\n",
    "                if( prediction_object[1] > 0.05):\n",
    "                    IOU = cal_IOU(prediction_object[2:],label_object[1:])\n",
    "                    if (IOU[0] > max_IOU):\n",
    "                        max_IOU = IOU[0]\n",
    "        prediction_object_count[label_object[0]] += 1\n",
    "        \n",
    "\n",
    "# test 200,200,400,400 & 300,300,500,500\n",
    "# 200,200,400,400 use yolo is (300,300,200,200) or (0.2467,0.2467,0.1645,0.1645)\n",
    "cal_IOU([200, 200, 400, 400], [300, 300, 500, 500])\n",
    "trans_yolo_label([0.2467, 0.2467, 0.1645, 0.1645])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_pic_info\n",
    "#dict_pic_label_box_info\n",
    "\n",
    "label_object_count = [0 for i in range(len(classes))]\n",
    "prediction_object_count = [0 for i in range(len(classes))]\n",
    "recalls = [0 for i in range(len(classes))]\n",
    "\n",
    "for pic_name in dict_pic_info:\n",
    "    predictions_in_single_pic = trans_strinfo_pediction(dict_pic_info[pic_name])\n",
    "    labels_in_single_pic = trans_strinfo_label(dict_pic_label_box_info[pic_name])\n",
    "    predictions_in_single_pic = delele_same_predictions(predictions_in_single_pic)\n",
    "    cal_recall_count(label_object_count, prediction_object_count, \n",
    "                     labels_in_single_pic, predictions_in_single_pic)\n",
    "\n",
    "for i, recall in enumerate(recalls):\n",
    "    if (label_object_count[i] != 0):\n",
    "        recalls[i] = prediction_object_count[i] / label_object_count[i]\n",
    "    else:\n",
    "        recalls[i] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCUS\t:\t499/603\t\trecall:\t0.8275290215588723\n",
      "LSIL\t:\t560/595\t\trecall:\t0.9411764705882353\n",
      "ASCH\t:\t146/161\t\trecall:\t0.906832298136646\n",
      "HSIL\t:\t599/659\t\trecall:\t0.9089529590288316\n",
      "SCC\t:\t143/163\t\trecall:\t0.8773006134969326\n",
      "AGC1\t:\t122/109\t\trecall:\t1.1192660550458715\n",
      "AGC2\t:\t58/44\t\trecall:\t1.3181818181818181\n",
      "ADC\t:\t94/94\t\trecall:\t1.0\n",
      "EC\t:\t42/39\t\trecall:\t1.0769230769230769\n",
      "FUNGI\t:\t95/86\t\trecall:\t1.1046511627906976\n",
      "TRI\t:\t36/82\t\trecall:\t0.43902439024390244\n",
      "CC\t:\t0/358\t\trecall:\t0.0\n",
      "ACTINO\t:\t323/301\t\trecall:\t1.0730897009966778\n",
      "VIRUS\t:\t97/93\t\trecall:\t1.043010752688172\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(class_name + \"\\t\" + \":\" + \n",
    "          \"\\t\" + str(prediction_object_count[i]) + \"/\" +\n",
    "          str(label_object_count[i]) + \n",
    "          \"\\t\\t\" + \"recall\" + \":\" + \"\\t\" + str(recalls[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
